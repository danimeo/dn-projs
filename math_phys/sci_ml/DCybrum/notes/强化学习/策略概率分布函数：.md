策略概率分布函数：
$$
\pi_\theta(s_t|\theta^\pi)
$$

马尔可夫决策过程：
$$
MDP=(\pmb{S}, \pmb{A}, \pmb{P}_{sa}, \pmb{R})
\\其中\pmb{S}为状态空间集，\\\pmb{A}为动作空间集，\\\pmb{P}_{sa}为状态s下执行动作a后，下一时间步中向各个状态转移的状态转移概率，\\\pmb{R}为奖励
$$
